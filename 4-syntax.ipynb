{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "allied-history",
   "metadata": {},
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-memphis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cytoolz import *\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-shopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", exclude=[\"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-consolidation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('s3://ling583/sentiment.parquet', storage_options={'anon': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-priest",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = DocBin().from_disk('parsed.docbin')\n",
    "df['doc'] = list(docs.get_docs(nlp.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-walnut",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-young",
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = train_test_split(df,\n",
    "                             test_size=0.2,\n",
    "                             stratify=df['sentiment'],\n",
    "                             random_state=619)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-worker",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-vietnam",
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(nlp(\"They didn't have any clean towels.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-hacker",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Token\n",
    "Token.set_extension('neg', default=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-european",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in df['doc']:\n",
    "    for t in doc:\n",
    "        if t.dep_ == 'neg':\n",
    "            t.head._.neg = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-occasions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_neg(token):\n",
    "    return 'NOT:'+token.norm_ if token._.neg else token.norm_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-console",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    return [add_neg(t) for t in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-interface",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = make_pipeline(CountVectorizer(preprocessor=identity, tokenizer=tokenize),\n",
    "                   TfidfTransformer(),\n",
    "                   SGDClassifier(alpha=1e-5))\n",
    "m1.fit(train['doc'], train['sentiment'])\n",
    "m1.score(test['doc'], test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-aurora",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_feats(M, k=0):\n",
    "    V = M.named_steps['countvectorizer'].get_feature_names()\n",
    "    coef = M.named_steps['sgdclassifier'].coef_[0]\n",
    "    order = coef.argsort()\n",
    "    for w1, w2 in zip(order[-k:][::-1],order[:k]):\n",
    "        print(f'{V[w1]:20s} {coef[w1]:7.3f} | {V[w2]:20s} {coef[w2]:7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-revelation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_top_feats(m1, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-savannah",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negify(tok):\n",
    "    tok._.neg = True\n",
    "    for child in tok.children:\n",
    "        negify(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-barrel",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in df['doc']:\n",
    "    for t in doc:\n",
    "        t._.neg = False\n",
    "    for t in doc:        \n",
    "        if t.dep_ == 'neg':\n",
    "            t.head._.neg = True\n",
    "            for r in t.head.rights:\n",
    "                if r.dep_ in ['acomp', 'advmod', 'attr', 'dobj', 'prep', 'xcomp']:\n",
    "                    negify(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = make_pipeline(CountVectorizer(preprocessor=identity, tokenizer=tokenize),\n",
    "                   TfidfTransformer(),\n",
    "                   SGDClassifier(alpha=1e-5))\n",
    "m2.fit(train['doc'], train['sentiment'])\n",
    "m2.score(test['doc'], test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-situation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_top_feats(m2, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-battle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod_tokenizer(doc):\n",
    "    return [ add_neg(w.head) + '_' + add_neg(w) for w in doc \n",
    "            if w.dep_ in ['amod', 'advmod'] ] + \\\n",
    "            [ add_neg(w) for w in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-creek",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_tokenizer(nlp(\"The didn't have any clean towels.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-satellite",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3 = make_pipeline(CountVectorizer(preprocessor=identity, tokenizer=mod_tokenizer),\n",
    "                   TfidfTransformer(),\n",
    "                   SGDClassifier(alpha=1e-5))\n",
    "m3.fit(train['doc'], train['sentiment'])\n",
    "m3.score(test['doc'], test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-budapest",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_top_feats(m3, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def everything(doc):\n",
    "    return [ add_neg(w.head) + '_' + add_neg(w) for w in doc ] + \\\n",
    "            [ add_neg(w) for w in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-delivery",
   "metadata": {},
   "outputs": [],
   "source": [
    "everything(nlp(\"The didn't have any clean towels.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-factory",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4 = make_pipeline(CountVectorizer(preprocessor=identity, tokenizer=everything),\n",
    "                   TfidfTransformer(),\n",
    "                   SGDClassifier(alpha=1e-5))\n",
    "m4.fit(train['doc'], train['sentiment'])\n",
    "m4.score(test['doc'], test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-boring",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_top_feats(m4, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-holocaust",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
