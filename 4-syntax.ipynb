{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "systematic-turkish",
   "metadata": {},
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "conscious-despite",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cytoolz import *\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "intermediate-namibia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", exclude=[\"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "announced-productivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('s3://ling583/sentiment.parquet', storage_options={'anon': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "parliamentary-student",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = DocBin().from_disk('parsed.docbin')\n",
    "df['doc'] = list(docs.get_docs(nlp.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bizarre-grain",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "comparable-surveillance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "romance-democrat",
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = train_test_split(df,\n",
    "                             test_size=0.2,\n",
    "                             stratify=df['sentiment'],\n",
    "                             random_state=619)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-kernel",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "collect-florida",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"2322605e494f4068a8cb7a11108c2e35-0\" class=\"displacy\" width=\"1275\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">They</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">did</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">n't</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">have</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">any</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">clean</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">towels.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2322605e494f4068a8cb7a11108c2e35-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,2.0 575.0,2.0 575.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2322605e494f4068a8cb7a11108c2e35-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2322605e494f4068a8cb7a11108c2e35-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,89.5 570.0,89.5 570.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2322605e494f4068a8cb7a11108c2e35-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2322605e494f4068a8cb7a11108c2e35-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2322605e494f4068a8cb7a11108c2e35-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">neg</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2322605e494f4068a8cb7a11108c2e35-0-3\" stroke-width=\"2px\" d=\"M770,264.5 C770,89.5 1095.0,89.5 1095.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2322605e494f4068a8cb7a11108c2e35-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2322605e494f4068a8cb7a11108c2e35-0-4\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2322605e494f4068a8cb7a11108c2e35-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M945,266.5 L937,254.5 953,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2322605e494f4068a8cb7a11108c2e35-0-5\" stroke-width=\"2px\" d=\"M595,264.5 C595,2.0 1100.0,2.0 1100.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2322605e494f4068a8cb7a11108c2e35-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1100.0,266.5 L1108.0,254.5 1092.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(nlp(\"They didn't have any clean towels.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "surprised-union",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Token\n",
    "Token.set_extension('neg', default=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "removed-blocking",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in df['doc']:\n",
    "    for t in doc:\n",
    "        if t.dep_ == 'neg':\n",
    "            t.head._.neg = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "norwegian-classroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_neg(token):\n",
    "    return 'NOT:'+token.norm_ if token._.neg else token.norm_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "advised-catalyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    return [add_neg(t) for t in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "lyric-produce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8991"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = make_pipeline(CountVectorizer(preprocessor=identity, tokenizer=tokenize),\n",
    "                   TfidfTransformer(),\n",
    "                   SGDClassifier(alpha=1e-5))\n",
    "m1.fit(train['doc'], train['sentiment'])\n",
    "m1.score(test['doc'], test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "premier-board",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_feats(M, k=0):\n",
    "    V = M.named_steps['countvectorizer'].get_feature_names()\n",
    "    coef = M.named_steps['sgdclassifier'].coef_[0]\n",
    "    order = coef.argsort()\n",
    "    for w1, w2 in zip(order[-k:][::-1],order[:k]):\n",
    "        print(f'{V[w1]:20s} {coef[w1]:7.3f} | {V[w2]:20s} {coef[w2]:7.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "upset-giving",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great                  5.446 | NOT:stay              -5.221\n",
      "loved                  4.941 | average               -4.982\n",
      "perfect                4.900 | ok                    -4.972\n",
      "excellent              4.496 | dirty                 -4.838\n",
      "amazing                4.317 | poor                  -4.648\n",
      "definitely             4.109 | unhelpful             -4.545\n",
      "wonderful              3.952 | ruined                -4.502\n",
      "comfortable            3.952 | tiny                  -4.357\n",
      "appointed              3.872 | not                   -4.246\n",
      "pleasantly             3.829 | worst                 -4.211\n",
      "minor                  3.751 | dated                 -4.190\n",
      "spacious               3.706 | filthy                -4.035\n",
      "NOT:beat               3.694 | terrible              -3.882\n",
      "downside               3.607 | dingy                 -3.858\n",
      "spotless               3.564 | outdated              -3.767\n",
      "complaint              3.470 | uncomfortable         -3.704\n",
      "elegant                3.441 | update                -3.702\n",
      "quiet                  3.419 | poorly                -3.677\n",
      "screen                 3.415 | updating              -3.482\n",
      "NOT:eat                3.396 | NOT:cleaned           -3.440\n",
      "lovely                 3.396 | rude                  -3.435\n",
      "NOT:disappointed       3.362 | stolen                -3.433\n",
      "recommend              3.304 | elsewhere             -3.431\n",
      "pleased                3.040 | nothing               -3.427\n",
      "slight                 3.034 | disappointing         -3.422\n"
     ]
    }
   ],
   "source": [
    "print_top_feats(m1, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "indirect-industry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negify(tok):\n",
    "    tok._.neg = True\n",
    "    for child in tok.children:\n",
    "        negify(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "public-session",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in df['doc']:\n",
    "    for t in doc:\n",
    "        t._.neg = False\n",
    "    for t in doc:        \n",
    "        if t.dep_ == 'neg':\n",
    "            t.head._.neg = True\n",
    "            for r in t.head.rights:\n",
    "                if r.dep_ in ['acomp', 'advmod', 'attr', 'dobj', 'prep', 'xcomp']:\n",
    "                    negify(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fitted-rebound",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9023"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = make_pipeline(CountVectorizer(preprocessor=identity, tokenizer=tokenize),\n",
    "                   TfidfTransformer(),\n",
    "                   SGDClassifier(alpha=1e-5))\n",
    "m2.fit(train['doc'], train['sentiment'])\n",
    "m2.score(test['doc'], test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "celtic-perspective",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great                  5.590 | dirty                 -5.071\n",
      "NOT:hesitate           5.416 | average               -4.767\n",
      "loved                  5.038 | poor                  -4.625\n",
      "perfect                4.572 | ok                    -4.564\n",
      "excellent              4.382 | ruined                -4.400\n",
      "comfortable            4.106 | dated                 -4.248\n",
      "wonderful              3.998 | disappointed          -4.232\n",
      "amazing                3.853 | not                   -4.186\n",
      "pleasantly             3.799 | outdated              -4.182\n",
      "downside               3.736 | unhelpful             -4.113\n",
      "NOT:better             3.703 | NOT:again             -4.060\n",
      "NOT:beat               3.691 | worst                 -4.033\n",
      "definitely             3.626 | terrible              -3.980\n",
      "spacious               3.620 | filthy                -3.912\n",
      "appointed              3.574 | tiny                  -3.809\n",
      "lovely                 3.559 | horrible              -3.648\n",
      "complaint              3.548 | uncomfortable         -3.628\n",
      "minor                  3.508 | rude                  -3.608\n",
      "elegant                3.338 | disappointing         -3.519\n",
      "pleased                3.334 | dingy                 -3.483\n",
      "spotless               3.319 | elsewhere             -3.467\n",
      "immaculate             3.305 | update                -3.463\n",
      "NOT:eat                3.291 | NOT:cleaned           -3.373\n",
      "fantastic              3.269 | worn                  -3.297\n",
      "quiet                  3.228 | attempt               -3.257\n"
     ]
    }
   ],
   "source": [
    "print_top_feats(m2, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "married-placement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod_tokenizer(doc):\n",
    "    return [ add_neg(w.head) + '_' + add_neg(w) for w in doc \n",
    "            if w.dep_ in ['amod', 'advmod'] ] + \\\n",
    "            [ add_neg(w) for w in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "technological-government",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['towels_clean', 'the', 'do', 'not', 'have', 'any', 'clean', 'towels', '.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_tokenizer(nlp(\"The didn't have any clean towels.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "exempt-engagement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9091"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3 = make_pipeline(CountVectorizer(preprocessor=identity, tokenizer=mod_tokenizer),\n",
    "                   TfidfTransformer(),\n",
    "                   SGDClassifier(alpha=1e-5))\n",
    "m3.fit(train['doc'], train['sentiment'])\n",
    "m3.score(test['doc'], test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "naval-friendship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT:hesitate           5.152 | dirty                 -4.827\n",
      "loved                  4.729 | average               -4.139\n",
      "great                  4.566 | ok                    -3.967\n",
      "perfect                4.331 | poor                  -3.950\n",
      "excellent              3.676 | terrible              -3.871\n",
      "lovely                 3.448 | worst                 -3.709\n",
      "quiet                  3.446 | tiny                  -3.705\n",
      "amazing                3.422 | ruined                -3.698\n",
      "wonderful              3.206 | filthy                -3.672\n",
      "immaculate             3.083 | unhelpful             -3.589\n",
      "NOT:disappointed       3.078 | not                   -3.588\n",
      "NOT:better             3.064 | dated                 -3.384\n",
      "thing_bad              3.036 | disappointed          -3.314\n",
      "NOT:eat                2.997 | outdated              -3.269\n",
      "NOT:beat               2.993 | horrible              -3.212\n",
      "spotless               2.939 | thing_best            -3.025\n",
      "downside               2.927 | rude                  -2.992\n",
      "minor                  2.917 | small_so              -2.965\n",
      "stay_again             2.853 | worn                  -2.948\n",
      "awesome                2.848 | told                  -2.930\n",
      "comfortable            2.822 | nothing               -2.801\n",
      "recommend              2.815 | attempt               -2.751\n",
      "spacious               2.793 | inadequate            -2.741\n",
      "enjoyed                2.791 | smell                 -2.731\n",
      "complaints             2.744 | uncomfortable         -2.705\n"
     ]
    }
   ],
   "source": [
    "print_top_feats(m3, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "electrical-baltimore",
   "metadata": {},
   "outputs": [],
   "source": [
    "def everything(doc):\n",
    "    return [ add_neg(w.head) + '_' + add_neg(w) for w in doc ] + \\\n",
    "            [ add_neg(w) for w in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "phantom-clone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['have_they',\n",
       " 'have_do',\n",
       " 'have_not',\n",
       " 'have_have',\n",
       " 'towels_any',\n",
       " 'towels_clean',\n",
       " 'have_towels',\n",
       " 'have_.',\n",
       " 'they',\n",
       " 'do',\n",
       " 'not',\n",
       " 'have',\n",
       " 'any',\n",
       " 'clean',\n",
       " 'towels',\n",
       " '.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "everything(nlp(\"They didn't have any clean towels.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "temporal-greeting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9116"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m4 = make_pipeline(CountVectorizer(preprocessor=identity, tokenizer=everything),\n",
    "                   TfidfTransformer(),\n",
    "                   SGDClassifier(alpha=1e-5))\n",
    "m4.fit(train['doc'], train['sentiment'])\n",
    "m4.score(test['doc'], test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "knowing-generic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great                  5.348 | average               -4.757\n",
      "excellent              4.115 | ok                    -4.620\n",
      "perfect                3.821 | dirty                 -4.309\n",
      "wonderful              3.489 | not                   -4.021\n",
      "comfortable            3.343 | poor                  -3.994\n",
      "amazing                3.231 | terrible              -3.573\n",
      "lovely                 3.153 | worst                 -3.520\n",
      "quiet                  3.086 | no                    -3.434\n",
      "clean_very             2.794 | tiny                  -3.239\n",
      "minor                  2.755 | rude                  -2.997\n",
      "definitely             2.748 | nothing               -2.952\n",
      "awesome                2.730 | disappointed          -2.945\n",
      "loved                  2.659 | dated                 -2.851\n",
      "comfortable_very       2.659 | horrible              -2.799\n",
      "appointed              2.463 | unhelpful             -2.661\n",
      "spacious               2.423 | bad                   -2.641\n",
      "fantastic              2.397 | NOT:again             -2.603\n",
      "modern                 2.369 | uncomfortable         -2.574\n",
      "beautiful              2.338 | worn                  -2.522\n",
      "comfy                  2.285 | in_need               -2.518\n",
      "immaculate             2.193 | need_of               -2.470\n",
      "outstanding            2.189 | unfriendly            -2.447\n",
      "best                   2.167 | elsewhere             -2.354\n",
      "free                   2.152 | carpet                -2.339\n",
      "pleasantly             2.149 | told                  -2.328\n",
      "NOT:better             2.149 | filthy                -2.306\n",
      "helpful                2.108 | okay                  -2.253\n",
      "nice                   2.099 | small_very            -2.246\n",
      "hotel_great            2.081 | old                   -2.213\n",
      "stay_again             2.078 | hotel_average         -2.190\n",
      "NOT:disappointed       2.075 | barely                -2.189\n",
      "everything             2.066 | poorly                -2.160\n",
      "spotless               2.060 | NOT:stay_NOT:again    -2.160\n",
      "got_for                2.036 | awful                 -2.153\n",
      "5                      1.996 | disappointing         -2.139\n",
      "elegant                1.989 | outdated              -2.124\n",
      "value_great            1.952 | smell                 -2.118\n",
      "be_back                1.939 | ruined                -2.084\n",
      "was_amazing            1.922 | stay_short            -2.054\n",
      "love_.                 1.907 | expensive_very        -2.047\n",
      "immediately            1.891 | dingy                 -2.035\n",
      "professional           1.870 | better                -2.034\n",
      "complaint_only         1.854 | dated_.               -2.032\n",
      "enjoyed                1.817 | stay_away             -2.016\n",
      "pleased                1.792 | small_so              -1.991\n",
      "was_perfect            1.772 | time_next             -1.987\n",
      "stay_definitely        1.772 | stay_elsewhere        -1.957\n",
      "complaints             1.756 | shabby                -1.951\n",
      "wine                   1.738 | tried                 -1.913\n",
      "value_for              1.737 | tired                 -1.901\n"
     ]
    }
   ],
   "source": [
    "print_top_feats(m4, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-operations",
   "metadata": {},
   "source": [
    "# Failed manual runs\n",
    "in ascending order of improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "opened-guard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8942"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m5 = make_pipeline(CountVectorizer(preprocessor=identity, \n",
    "                                   tokenizer=everything, \n",
    "                                   max_df=0.7,\n",
    "                                   min_df=12),\n",
    "                   TfidfTransformer(),\n",
    "                   SGDClassifier(alpha=1e-6))\n",
    "m5.fit(train['doc'], train['sentiment'])\n",
    "m5.score(test['doc'], test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "interesting-lodge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9053"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m5 = make_pipeline(CountVectorizer(preprocessor=identity, \n",
    "                                   tokenizer=everything, \n",
    "                                   max_df=0.7,\n",
    "                                   min_df=10),\n",
    "                   TfidfTransformer(),\n",
    "                   SGDClassifier(alpha=1e-5))\n",
    "m5.fit(train['doc'], train['sentiment'])\n",
    "m5.score(test['doc'], test['sentiment'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-champagne",
   "metadata": {},
   "outputs": [],
   "source": [
    "m5 = make_pipeline(CountVectorizer(preprocessor=identity, \n",
    "                                   tokenizer=everything, \n",
    "                                   max_df=0.7),\n",
    "                   TfidfTransformer(),\n",
    "                   SGDClassifier(alpha=1e-6))\n",
    "m5.fit(train['doc'], train['sentiment'])\n",
    "m5.score(test['doc'], test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-detail",
   "metadata": {},
   "outputs": [],
   "source": [
    "m5 = make_pipeline(CountVectorizer(preprocessor=identity, \n",
    "                                   tokenizer=everything, \n",
    "                                   max_df=0.7),\n",
    "                   TfidfTransformer(),\n",
    "                   SGDClassifier(alpha=2e-6))\n",
    "m5.fit(train['doc'], train['sentiment'])\n",
    "m5.score(test['doc'], test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-binding",
   "metadata": {},
   "outputs": [],
   "source": [
    "m5 = make_pipeline(CountVectorizer(preprocessor=identity, \n",
    "                                   tokenizer=everything, \n",
    "                                   max_df=0.7,\n",
    "                                   min_df=8),\n",
    "                   TfidfTransformer(),\n",
    "                   SGDClassifier(alpha=2e-5))\n",
    "m5.fit(train['doc'], train['sentiment'])\n",
    "m5.score(test['doc'], test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-athens",
   "metadata": {},
   "outputs": [],
   "source": [
    "m5 = make_pipeline(CountVectorizer(preprocessor=identity, \n",
    "                                   tokenizer=everything, \n",
    "                                   max_df=0.5,\n",
    "                                   min_df=10),\n",
    "                   TfidfTransformer(),\n",
    "                   SGDClassifier(alpha=2e-5))\n",
    "m5.fit(train['doc'], train['sentiment'])\n",
    "m5.score(test['doc'], test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-drunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "m5 = make_pipeline(CountVectorizer(preprocessor=identity, \n",
    "                                   tokenizer=everything, \n",
    "                                   max_df=0.7),\n",
    "                   TfidfTransformer(),\n",
    "                   SGDClassifier(alpha=1e-5))\n",
    "m5.fit(train['doc'], train['sentiment'])\n",
    "m5.score(test['doc'], test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-ending",
   "metadata": {},
   "outputs": [],
   "source": [
    "m5 = make_pipeline(CountVectorizer(preprocessor=identity, \n",
    "                                   tokenizer=everything, \n",
    "                                   max_df=0.7,\n",
    "                                   min_df=12),\n",
    "                   TfidfTransformer(),\n",
    "                   SGDClassifier(alpha=3e-5))\n",
    "m5.fit(train['doc'], train['sentiment'])\n",
    "m5.score(test['doc'], test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-clearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "m5 = make_pipeline(CountVectorizer(preprocessor=identity, \n",
    "                                   tokenizer=everything, \n",
    "                                   max_df=0.7,\n",
    "                                   min_df=14),\n",
    "                   TfidfTransformer(),\n",
    "                   SGDClassifier(alpha=2e-5))\n",
    "m5.fit(train['doc'], train['sentiment'])\n",
    "m5.score(test['doc'], test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gorgeous-credit",
   "metadata": {},
   "outputs": [],
   "source": [
    "m5 = make_pipeline(CountVectorizer(preprocessor=identity, \n",
    "                                   tokenizer=everything, \n",
    "                                   max_df=0.9,\n",
    "                                   min_df=10),\n",
    "                   TfidfTransformer(),\n",
    "                   SGDClassifier(alpha=2e-5))\n",
    "m5.fit(train['doc'], train['sentiment'])\n",
    "m5.score(test['doc'], test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-bridal",
   "metadata": {},
   "outputs": [],
   "source": [
    "m5 = make_pipeline(CountVectorizer(preprocessor=identity, \n",
    "                                   tokenizer=everything, \n",
    "                                   max_df=0.8,\n",
    "                                   min_df=10),\n",
    "                   TfidfTransformer(),\n",
    "                   SGDClassifier(alpha=2e-5))\n",
    "m5.fit(train['doc'], train['sentiment'])\n",
    "m5.score(test['doc'], test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fifteen-toyota",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9128"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m5 = make_pipeline(CountVectorizer(preprocessor=identity, \n",
    "                                   tokenizer=everything, \n",
    "                                   max_df=0.9,\n",
    "                                   min_df=12),\n",
    "                   TfidfTransformer(),\n",
    "                   SGDClassifier(alpha=2e-5))\n",
    "m5.fit(train['doc'], train['sentiment'])\n",
    "m5.score(test['doc'], test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "individual-gambling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9124"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m5 = make_pipeline(CountVectorizer(preprocessor=identity, \n",
    "                                   tokenizer=everything, \n",
    "                                   max_df=0.7,\n",
    "                                   min_df=10),\n",
    "                   TfidfTransformer(),\n",
    "                   SGDClassifier(alpha=2e-5))\n",
    "m5.fit(train['doc'], train['sentiment'])\n",
    "m5.score(test['doc'], test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "classical-cleaners",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9124"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m5 = make_pipeline(CountVectorizer(preprocessor=identity, \n",
    "                                   tokenizer=everything, \n",
    "                                   max_df=0.7,\n",
    "                                   min_df=12),\n",
    "                   TfidfTransformer(),\n",
    "                   SGDClassifier(alpha=2e-5))\n",
    "m5.fit(train['doc'], train['sentiment'])\n",
    "m5.score(test['doc'], test['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "existing-eugene",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9126"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m5 = make_pipeline(CountVectorizer(preprocessor=identity, \n",
    "                                   tokenizer=everything, \n",
    "                                   max_df=0.8,\n",
    "                                   min_df=10),\n",
    "                   TfidfTransformer(),\n",
    "                   SGDClassifier(alpha=3e-5))\n",
    "m5.fit(train['doc'], train['sentiment'])\n",
    "m5.score(test['doc'], test['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-point",
   "metadata": {},
   "source": [
    "# Best manual runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "republican-index",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9131"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m5 = make_pipeline(CountVectorizer(preprocessor=identity, \n",
    "                                   tokenizer=everything, \n",
    "                                   max_df=0.8,\n",
    "                                   min_df=10),\n",
    "                   TfidfTransformer(),\n",
    "                   SGDClassifier(alpha=4e-5))\n",
    "m5.fit(train['doc'], train['sentiment'])\n",
    "m5.score(test['doc'], test['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-speaker",
   "metadata": {},
   "source": [
    "# Compare to our first classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "lovely-return",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_predicted = m1.predict(test[\"doc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "applied-regulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = m5.predict(test[\"doc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "limiting-watts",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_f1 = f1_score(test[\"sentiment\"], base_predicted, average=\"macro\")\n",
    "sgd_f1 = f1_score(test[\"sentiment\"], predicted, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "opposed-accountability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base F1 score: 0.8667684233550119\n",
      "SGD F1 score:  0.8847607251396229\n",
      "Difference:    0.017992301784610976\n",
      "Improvement:   0.1350453266236853\n"
     ]
    }
   ],
   "source": [
    "print(f\"Base F1 score: {base_f1}\")\n",
    "print(f\"SGD F1 score:  {sgd_f1}\")\n",
    "print(f\"Difference:    {sgd_f1 - base_f1}\") \n",
    "print(f\"Improvement:   {(sgd_f1 - base_f1) / (1 - base_f1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-orleans",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
